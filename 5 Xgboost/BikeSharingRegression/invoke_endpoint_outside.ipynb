{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke SageMaker Enpoint from outside of AWS environment using SageMaker SDK\n",
    "\n",
    "Model used: XGBoost Bike Rental Prediction Trained in the XGBoost Lectures  \n",
    "  \n",
    "This example uses the IAM user: ml_user_predict. The user was setup in the housekeeping lecture of the course.  \n",
    "\n",
    "Refer to the lecture: Configure IAM Users, Setup Command Line Interface (CLI)\n",
    "\n",
    "Ensure xgboost-biketrain-v1 Endpoint is deployed before running this example  \n",
    "  \n",
    "To create an endpoint using SageMaker Console:  \n",
    "1. Select \"Models\" under \"Inference\" in navigation pane\n",
    "2. Search for model using this prefix: xgboost-biketrain-v1\n",
    "3. Select the latest model and choose create endpoint\n",
    "4. Specify endpoint name as: xgboost-biketrain-v1\n",
    "5. Create a new endpoint configuration\n",
    "6. Create a new endpoint\n",
    "7. After this lab is completed, delete the endpoint to avoid unnecessary charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sagemaker\n",
      "  Downloading sagemaker-2.59.0.tar.gz (440 kB)\n",
      "Requirement already satisfied, skipping upgrade: attrs in c:\\programdata\\anaconda3\\lib\\site-packages (from sagemaker) (18.1.0)\n",
      "Collecting boto3>=1.16.32\n",
      "  Downloading boto3-1.18.34-py3-none-any.whl (131 kB)\n",
      "Collecting google-pasta\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sagemaker) (1.19.2)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from sagemaker) (3.16.0)\n",
      "Collecting protobuf3-to-dict>=0.1.5\n",
      "  Downloading protobuf3-to-dict-0.1.5.tar.gz (3.5 kB)\n",
      "Collecting smdebug_rulesconfig==1.0.1\n",
      "  Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata>=1.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sagemaker) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sagemaker) (20.4)\n",
      "Requirement already satisfied, skipping upgrade: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (from sagemaker) (1.1.3)\n",
      "Collecting pathos\n",
      "  Downloading pathos-0.2.8-py2.py3-none-any.whl (81 kB)\n",
      "Collecting s3transfer<0.6.0,>=0.5.0\n",
      "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
      "Collecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting botocore<1.22.0,>=1.21.34\n",
      "  Downloading botocore-1.21.34-py3-none-any.whl (7.9 MB)\n",
      "Requirement already satisfied, skipping upgrade: six in c:\\programdata\\anaconda3\\lib\\site-packages (from google-pasta->sagemaker) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata>=1.4.0->sagemaker) (3.4.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->sagemaker) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->sagemaker) (2020.1)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->sagemaker) (2.8.1)\n",
      "Collecting multiprocess>=0.70.12\n",
      "  Downloading multiprocess-0.70.12.2-py38-none-any.whl (128 kB)\n",
      "Collecting pox>=0.3.0\n",
      "  Downloading pox-0.3.0-py2.py3-none-any.whl (30 kB)\n",
      "Collecting dill>=0.3.4\n",
      "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
      "Collecting ppft>=1.6.6.4\n",
      "  Downloading ppft-1.6.6.4-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.27,>=1.25.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from botocore<1.22.0,>=1.21.34->boto3>=1.16.32->sagemaker) (1.25.11)\n",
      "Building wheels for collected packages: sagemaker, protobuf3-to-dict\n",
      "  Building wheel for sagemaker (setup.py): started\n",
      "  Building wheel for sagemaker (setup.py): finished with status 'done'\n",
      "  Created wheel for sagemaker: filename=sagemaker-2.59.0-py2.py3-none-any.whl size=616376 sha256=7deec5abecdbc063b4369b3c8dec8b07fb41ca393e33398fef2129ef5542668b\n",
      "  Stored in directory: c:\\users\\jaiprakash.prajapati\\appdata\\local\\pip\\cache\\wheels\\ff\\f8\\9f\\331eaceca75cc96966457cddce3ae2cbd02295f9d285884194\n",
      "  Building wheel for protobuf3-to-dict (setup.py): started\n",
      "  Building wheel for protobuf3-to-dict (setup.py): finished with status 'done'\n",
      "  Created wheel for protobuf3-to-dict: filename=protobuf3_to_dict-0.1.5-py3-none-any.whl size=4033 sha256=da82f705f957b6920fda28d183a2b6e425aec065889adf71c6456d9e37fd94fa\n",
      "  Stored in directory: c:\\users\\jaiprakash.prajapati\\appdata\\local\\pip\\cache\\wheels\\fc\\10\\27\\2d1e23d8b9a9013a83fbb418a0b17b1e6f81c8db8f53b53934\n",
      "Successfully built sagemaker protobuf3-to-dict\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3, google-pasta, protobuf3-to-dict, smdebug-rulesconfig, dill, multiprocess, pox, ppft, pathos, sagemaker\n",
      "Successfully installed boto3-1.18.34 botocore-1.21.34 dill-0.3.4 google-pasta-0.2.0 jmespath-0.10.0 multiprocess-0.70.12.2 pathos-0.2.8 pox-0.3.0 ppft-1.6.6.4 protobuf3-to-dict-0.1.5 s3transfer-0.5.0 sagemaker-2.59.0 smdebug-rulesconfig-1.0.1\n"
     ]
    }
   ],
   "source": [
    "# Install SageMaker 2.x version.\n",
    "!pip install --upgrade sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#define IAM role\n",
    "import boto3\n",
    "import re\n",
    "import sagemaker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a session with AWS\n",
    "# Specify credentials and region to be used for this session.\n",
    "# We will use a ml_user_predict credentials that has limited privileges\n",
    "boto_session = boto3.Session(profile_name='ml_predict',region_name='us-east-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session(boto_session=boto_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a predictor and point to an existing endpoint\n",
    "\n",
    "# Get Predictor using SageMaker SDK\n",
    "# Specify Your Endpoint Name\n",
    "endpoint_name = 'xgboost-bikerental-v1' \n",
    "\n",
    "predictor = sagemaker.predictor.Predictor(endpoint_name=endpoint_name,\n",
    "                                                 sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are sending data for inference in CSV format\n",
    "# # SDK 2 serializers and deserializers\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor.serializer = CSVSerializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datetime,season,holiday,workingday,weather,temp,atemp,humidity,windspeed\n",
    "# Actual=562\n",
    "sample_one = '2012-12-19 17:00:00,4,0,1,1,16.4,20.455,50,26.0027'\n",
    "# Actual=569\n",
    "sample_two = '2012-12-19 18:00:00,4,0,1,1,15.58,19.695,50,23.9994'\n",
    "# Actual=4\n",
    "sample_three = '2012-12-10 01:00:00,4,0,1,2,14.76,18.94,100,0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw Data Structure: \n",
    "# datetime,season,holiday,workingday,weather,temp,atemp,humidity,windspeed,casual,registered,count\n",
    "\n",
    "# Model expects data in this format (it was trained with these features):\n",
    "# season,holiday,workingday,weather,temp,atemp,humidity,windspeed,year,month,day,dayofweek,hour\n",
    "\n",
    "import math\n",
    "import dateutil\n",
    "\n",
    "def transform_data(data):\n",
    "    features = data.split(',')\n",
    "    \n",
    "    # Extract year, month, day, dayofweek, hour\n",
    "    dt = dateutil.parser.parse(features[0])\n",
    "\n",
    "    features.append(str(dt.year))\n",
    "    features.append(str(dt.month))\n",
    "    features.append(str(dt.day))\n",
    "    features.append(str(dt.weekday()))\n",
    "    features.append(str(dt.hour))\n",
    "    \n",
    "    # Return the transformed data. skip datetime field\n",
    "    return ','.join(features[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data:\n",
      " 2012-12-19 17:00:00,4,0,1,1,16.4,20.455,50,26.0027\n",
      "Transformed Data:\n",
      " 4,0,1,1,16.4,20.455,50,26.0027,2012,12,19,2,17\n"
     ]
    }
   ],
   "source": [
    "print('Raw Data:\\n',sample_one)\n",
    "print('Transformed Data:\\n',transform_data(sample_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'573.6282958984375'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's invoke prediction now\n",
    "predictor.predict(transform_data(sample_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Count 1.329240521840346e+249\n"
     ]
    }
   ],
   "source": [
    "# # Actual Count is 562...but predicted is 6.3.\n",
    "\n",
    "# # Model was trained with log1p(count)\n",
    "# # So, we need to apply inverse transformation to get the actual count\n",
    "# # Predicted Count looks much better now\n",
    "# result = predictor.predict(transform_data(sample_one))\n",
    "# result = result.decode(\"utf-8\")\n",
    "# print ('Predicted Count', math.expm1(float(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to send multiple samples\n",
    "result = predictor.predict([transform_data(sample_one), transform_data(sample_two)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'573.6282958984375,547.5216064453125'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result #.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Batch Prediction\n",
    "# # Transform data and invoke prediction in specified batch sizes\n",
    "# def run_predictions(data, batch_size):\n",
    "#     predictions = []\n",
    "    \n",
    "#     transformed_data = [transform_data(row.strip()) for row in data]\n",
    "    \n",
    "#     for i in range(0, len(data), batch_size):\n",
    "        \n",
    "#         print(i,i+batch_size)\n",
    "        \n",
    "#         result = predictor.predict(transformed_data[i : i + batch_size])\n",
    "        \n",
    "#         result = result #.decode(\"utf-8\")\n",
    "#         result = result.split(',')\n",
    "        \n",
    "#         predictions += [math.expm1(float(r)) for r in result]\n",
    "                \n",
    "#     return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_predictions([sample_one,sample_two,sample_three],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a batch prediction on Test.CSV File\n",
    "# Read the file content\n",
    "data = []\n",
    "with open('test.csv','r') as f:\n",
    "    # skip header\n",
    "    f.readline()\n",
    "    # Read remaining lines\n",
    "    data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6493"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 500\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-16bf428ab074>\u001b[0m in \u001b[0;36mrun_predictions\u001b[1;34m(data, batch_size)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;31m#.decode(\"utf-8\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpm1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = run_predictions(data,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6493, 6493)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions),len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't forget to delete the endpoint\n",
    "# From SageMaker Console, Select \"Endpoints\" under Inference and Delete the Endpoint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
