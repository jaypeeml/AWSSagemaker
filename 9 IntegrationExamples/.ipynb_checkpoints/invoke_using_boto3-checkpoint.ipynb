{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boto3 SageMaker Invoke Endpoint\n",
    "# This example shows how to invoke SageMaker Endpoint from outside of AWS environment using Boto3 SDK\n",
    "# Boto is the Amazon Web Services (AWS) SDK for Python\n",
    "# https://boto3.amazonaws.com/v1/documentation/api/latest/index.html\n",
    "\n",
    "# Endpoint: XGBoost - Kaggle Bike Rental - Regressor Trained in XGBoost Lectures\n",
    "# Makesure Endpoint is deployed before running this example\n",
    "# \n",
    "# Reference:\n",
    "#  https://github.com/awslabs/amazon-sagemaker-examples\n",
    "\n",
    "# NOTE: SageMaker SDK now requires additional permissions DescribeEndpoint, DescribeEndpointConfig in-addition to InvokeEndpoint\n",
    "#   boto3 SDK requires just InvokeEndpoint permission.\n",
    "#   Please update SageMakerInvokeEndpoint permissions to reflect this policy document:\n",
    "#   Logon with my_admin account and update permissions (IAM->Policies->SageMakerInvokeEndpoint->Edit Policy)\n",
    "#   \n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"VisualEditor0\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"sagemaker:DescribeEndpointConfig\",\n",
    "                \"sagemaker:DescribeEndpoint\",\n",
    "                \"sagemaker:InvokeEndpoint\"\n",
    "            ],\n",
    "            \"Resource\": \"*\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import math\n",
    "import dateutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a session with AWS\n",
    "# Specify credentials and region to be used for this session.\n",
    "# We will use a ml_user_predict credentials that has limited privileges\n",
    "boto_session = boto3.Session(profile_name='ml_user',region_name='us-east-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accessanalyzer', 'acm', 'acm-pca', 'alexaforbusiness', 'amp', 'amplify', 'amplifybackend', 'apigateway', 'apigatewaymanagementapi', 'apigatewayv2', 'appconfig', 'appflow', 'appintegrations', 'application-autoscaling', 'application-insights', 'applicationcostprofiler', 'appmesh', 'apprunner', 'appstream', 'appsync', 'athena', 'auditmanager', 'autoscaling', 'autoscaling-plans', 'backup', 'batch', 'braket', 'budgets', 'ce', 'chime', 'chime-sdk-identity', 'chime-sdk-messaging', 'cloud9', 'clouddirectory', 'cloudformation', 'cloudfront', 'cloudhsm', 'cloudhsmv2', 'cloudsearch', 'cloudsearchdomain', 'cloudtrail', 'cloudwatch', 'codeartifact', 'codebuild', 'codecommit', 'codedeploy', 'codeguru-reviewer', 'codeguruprofiler', 'codepipeline', 'codestar', 'codestar-connections', 'codestar-notifications', 'cognito-identity', 'cognito-idp', 'cognito-sync', 'comprehend', 'comprehendmedical', 'compute-optimizer', 'config', 'connect', 'connect-contact-lens', 'connectparticipant', 'cur', 'customer-profiles', 'databrew', 'dataexchange', 'datapipeline', 'datasync', 'dax', 'detective', 'devicefarm', 'devops-guru', 'directconnect', 'discovery', 'dlm', 'dms', 'docdb', 'ds', 'dynamodb', 'dynamodbstreams', 'ebs', 'ec2', 'ec2-instance-connect', 'ecr', 'ecr-public', 'ecs', 'efs', 'eks', 'elastic-inference', 'elasticache', 'elasticbeanstalk', 'elastictranscoder', 'elb', 'elbv2', 'emr', 'emr-containers', 'es', 'events', 'finspace', 'finspace-data', 'firehose', 'fis', 'fms', 'forecast', 'forecastquery', 'frauddetector', 'fsx', 'gamelift', 'glacier', 'globalaccelerator', 'glue', 'greengrass', 'greengrassv2', 'groundstation', 'guardduty', 'health', 'healthlake', 'honeycode', 'iam', 'identitystore', 'imagebuilder', 'importexport', 'inspector', 'iot', 'iot-data', 'iot-jobs-data', 'iot1click-devices', 'iot1click-projects', 'iotanalytics', 'iotdeviceadvisor', 'iotevents', 'iotevents-data', 'iotfleethub', 'iotsecuretunneling', 'iotsitewise', 'iotthingsgraph', 'iotwireless', 'ivs', 'kafka', 'kendra', 'kinesis', 'kinesis-video-archived-media', 'kinesis-video-media', 'kinesis-video-signaling', 'kinesisanalytics', 'kinesisanalyticsv2', 'kinesisvideo', 'kms', 'lakeformation', 'lambda', 'lex-models', 'lex-runtime', 'lexv2-models', 'lexv2-runtime', 'license-manager', 'lightsail', 'location', 'logs', 'lookoutequipment', 'lookoutmetrics', 'lookoutvision', 'machinelearning', 'macie', 'macie2', 'managedblockchain', 'marketplace-catalog', 'marketplace-entitlement', 'marketplacecommerceanalytics', 'mediaconnect', 'mediaconvert', 'medialive', 'mediapackage', 'mediapackage-vod', 'mediastore', 'mediastore-data', 'mediatailor', 'memorydb', 'meteringmarketplace', 'mgh', 'mgn', 'migrationhub-config', 'mobile', 'mq', 'mturk', 'mwaa', 'neptune', 'network-firewall', 'networkmanager', 'nimble', 'opsworks', 'opsworkscm', 'organizations', 'outposts', 'personalize', 'personalize-events', 'personalize-runtime', 'pi', 'pinpoint', 'pinpoint-email', 'pinpoint-sms-voice', 'polly', 'pricing', 'proton', 'qldb', 'qldb-session', 'quicksight', 'ram', 'rds', 'rds-data', 'redshift', 'redshift-data', 'rekognition', 'resource-groups', 'resourcegroupstaggingapi', 'robomaker', 'route53', 'route53-recovery-cluster', 'route53-recovery-control-config', 'route53-recovery-readiness', 'route53domains', 'route53resolver', 's3', 's3control', 's3outposts', 'sagemaker', 'sagemaker-a2i-runtime', 'sagemaker-edge', 'sagemaker-featurestore-runtime', 'sagemaker-runtime', 'savingsplans', 'schemas', 'sdb', 'secretsmanager', 'securityhub', 'serverlessrepo', 'service-quotas', 'servicecatalog', 'servicecatalog-appregistry', 'servicediscovery', 'ses', 'sesv2', 'shield', 'signer', 'sms', 'sms-voice', 'snow-device-management', 'snowball', 'sns', 'sqs', 'ssm', 'ssm-contacts', 'ssm-incidents', 'sso', 'sso-admin', 'sso-oidc', 'stepfunctions', 'storagegateway', 'sts', 'support', 'swf', 'synthetics', 'textract', 'timestream-query', 'timestream-write', 'transcribe', 'transfer', 'translate', 'waf', 'waf-regional', 'wafv2', 'wellarchitected', 'workdocs', 'worklink', 'workmail', 'workmailmessageflow', 'workspaces', 'xray']\n"
     ]
    }
   ],
   "source": [
    "# List of low level clients that are available in boto3\n",
    "print(boto_session.get_available_services())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire a SageMaker Runtime client for us-east-1 region\n",
    "client = boto_session.client(service_name='sagemaker-runtime',region_name='us-east-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify Your Endpoint Name\n",
    "endpoint_name = 'xgboost-bikerental-v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw Data\n",
    "#datetime,season,holiday,workingday,weather,temp,atemp,humidity,windspeed,casual,registered,count\n",
    "# Actual=562\n",
    "sample_one = '2012-12-19 17:00:00,4,0,1,1,16.4,20.455,50,26.0027'\n",
    "# Actual=569\n",
    "sample_two = '2012-12-19 18:00:00,4,0,1,1,15.58,19.695,50,23.9994'\n",
    "# Actual=4\n",
    "sample_three = '2012-12-10 01:00:00,4,0,1,2,14.76,18.94,100,0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw Data Structure: \n",
    "# datetime,season,holiday,workingday,weather,temp,atemp,humidity,windspeed,casual,registered,count\n",
    "\n",
    "# Model expects data in this format (it was trained with these features):\n",
    "# season,holiday,workingday,weather,temp,atemp,humidity,windspeed,year,month,day,dayofweek,hour\n",
    "\n",
    "def transform_data(data):\n",
    "    features = data.split(',')\n",
    "    \n",
    "    # Extract year, month, day, dayofweek, hour\n",
    "    dt = dateutil.parser.parse(features[0])\n",
    "\n",
    "    features.append(str(dt.year))\n",
    "    features.append(str(dt.month))\n",
    "    features.append(str(dt.day))\n",
    "    features.append(str(dt.weekday()))\n",
    "    features.append(str(dt.hour))\n",
    "    \n",
    "    # Return the transformed data. skip datetime field\n",
    "    return ','.join(features[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Raw Data:\\n',sample_one)\n",
    "print('Transformed Data:\\n',transform_data(sample_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's invoke prediction now\n",
    "result = client.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                       Body=transform_data(sample_one).encode('utf-8'),\n",
    "                       ContentType='text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result['Body'].read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual Count is 562...but predicted is 6.36.\n",
    "\n",
    "# Model was trained with log1p(count)\n",
    "# So, we need to apply inverse transformation to get the actual count\n",
    "# Predicted Count looks much better now\n",
    "print ('Predicted Count', math.expm1(float(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n'.join([transform_data(sample_one),transform_data(sample_two)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction for multiple observations in the same call\n",
    "result = client.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                       Body=('\\n'.join([transform_data(sample_one),\n",
    "                                        transform_data(sample_two)]).encode('utf-8')),\n",
    "                       ContentType='text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result['Body'].read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Prediction\n",
    "# Transform data and invoke prediction in specified batch sizes\n",
    "def run_predictions(data, batch_size):\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    transformed_data = [transform_data(row.strip()) for row in data]\n",
    "    \n",
    "    for i in range(0, len(data), batch_size):\n",
    "        \n",
    "        print(i,i+batch_size)\n",
    "        \n",
    "        result = client.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                       Body=('\\n'.join(transformed_data[i : i + batch_size]).encode('utf-8')),\n",
    "                       ContentType='text/csv')\n",
    "        \n",
    "        result = result['Body'].read().decode('utf-8')\n",
    "        result = result.split(',')\n",
    "        \n",
    "        predictions += [math.expm1(float(r)) for r in result]\n",
    "                \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_predictions([sample_one,sample_two,sample_three],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a batch prediction on Test.CSV File\n",
    "# Read the file content\n",
    "data = []\n",
    "with open('test.csv','r') as f:\n",
    "    # skip header\n",
    "    f.readline()\n",
    "    # Read remaining lines\n",
    "    data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions = run_predictions(data,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions),len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
